


# Loading the dataset

import pandas as pd
import json

path = 'datasets/kaggle/fake_or_real_news.csv'

def load_dataset(dataset_path):
    return pd.read_csv(dataset_path, on_bad_lines='skip')


dataset_df= load_dataset(path)

dataset_df.head(10)





## TODO: How to print this information in a better way? Maybe using markdown

# Typecasting df to list 
dataset_df_list = list(dataset_df) 
  

print("There are " + str(len(dataset_df_list)) + " rows in the dataset being them: ") 
dataset_df.columns


print("There are " + str(len(dataset_df.index)) + " number of rows in the dataset")





# I can see below that the amount of unique values in 'Unnamed: 0' is the same number of rows in the dataset, with this information
# I can assume it is indeed an unique id.
dataset_df['Unnamed: 0'].nunique()


# so I will rename the column to ID so we can give a better name to it.Renaming 'unnamed: 0' to ID so we can give a name to it.
# dataset_df = dataset_df.rename(columns={"Unnamed: 0": "ID"}).sort_values(by="ID", axis=0)
dataset_df.head()


## TODO: FIX

# Creating a word cloud for the news articles
# !pip install wordcloud

from wordcloud import WordCloud
# Start with one review:
text = dataset_df.text[0]

# Create and generate a word cloud image:
wordcloud = WordCloud().generate(text)

# texts = " ".join(text for text in dataset_df["text"])

wc = WordCloud(collocations=False, background_color='white', width=2048, height=1080).generate(texts)
plt.imshow(wc, interpolation='bilinear')
plt.axis("off")
plt.show()








# Setting the features we are going to use to train our model: the text, title and label columns
texts = dataset_df['text'].values
titles = dataset_df['title'].values
labels = dataset_df['label'].values


# Training the model on the text articles in the dataset
from sklearn.feature_extraction.text import CountVectorizer

# Converting to vectors
def vectorize_data(data):
    vectorizer = CountVectorizer()
    vectors = vectorizer.fit_transform(data)
    return vectors;

vectorized_texts = vectorize_data(texts)


# Split the data into a training set and a test set using the vectors, using 50% of the data for the test size
from sklearn.model_selection import train_test_split

X_train_texts, X_test_texts, y_train_texts, y_test_texts = train_test_split(vectorized_texts, labels, test_size=0.50, random_state=42)


# Fake news classifier using sklearn and Multinomial Naives Bayern

# Train the model
from sklearn.naive_bayes import MultinomialNB

def train(X_train, y_train):
    model = MultinomialNB()
    model.fit(X_train, y_train)

    return model;


model  = train(X_train_texts, y_train_texts);


# Testing the model using the test data
y_pred_texts = model.predict(X_test_texts)

results_texts['prediction'] = y_pred ## Adding the prediction in a new column so we can compare

results_texts.head(100)


## Now training in the model using the title column
vectorized_titles = vectorize_data(titles)

# Splitting the data
X_train_titles, X_test_titles, y_train_titles, y_test_titles = train_test_split(vectorized_titles, labels, test_size=0.33, random_state=42)

# Training the model
model = train(X_train_titles, y_train_titles)

# Testing the trained model against the test data
y_pred_titles =  model.predict(X_test_titles)

## Adding the prediction in a new column so we can compare
results_titles['prediction'] = y_pred_titles
results_titles.head(100)





# Evaluating the accuracy of the model comparing the test and prediction data
import numpy as np
from sklearn.metrics import accuracy_score, confusion_matrix

def calculate_accuracy(y_pred, y_test):
    accuracy = accuracy_score(y_test, y_pred)
    return accuracy

# Printing the accuracy of the model on top of the texts and title features
print("Text fake news classification using Multinomial Naives Bayes:" + str(calculate_accuracy(y_test_texts, y_pred_texts)))
print("Titles fake news classification using Multinomial Naives Bayes:" + str(calculate_accuracy(y_test_titles, y_pred_titles)))

# Printing the confusion matrices
print("Confusion matrix for the text feature prediction: \n" + str(confusion_matrix(y_test_texts, y_pred_texts, labels=['FAKE', 'REAL'])))
print(("Confusion matrix for the title feature prediction: \n" + str(confusion_matrix(y_test_titles, y_pred_titles, labels=['FAKE', 'REAL']))))






